{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "md_reference_data = None\n",
    "upstream = None\n",
    "product = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R23 - MD alignment and RMSD extraction \n",
    "\n",
    "## Contents\n",
    "\n",
    "1. Alignment\n",
    "2. RMSD\n",
    "3. RMSD against average structure\n",
    "4. RMSD over subunit\n",
    "5. RMSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaustubh/miniconda3/envs/md-analysis/lib/python3.10/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mdtools.mapping import map_alignment_to_structure, align_structure_sequences\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis import rms, align\n",
    "from pyfamsa import Aligner, Sequence\n",
    "import json\n",
    "import pandas as pd\n",
    "import prody as pdy\n",
    "#matplotlib.rcParams['fontname'] = \"Arial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trajectory(code, data, path):\n",
    "    \n",
    "    \"\"\"\n",
    "    loads the following files\n",
    "    - an MDAnalysis trajectory with the dried (water-removed) dcd\n",
    "    - an MDAnalysis Universe with the starting PDB (jic)\n",
    "    - an prody with the starting PDB (pretty useful when MDAnalysis fails)\n",
    "    \"\"\"\n",
    "    return dict(\n",
    "        code=code,\n",
    "        trajectory_dry = mda.Universe(\n",
    "            path + data['dry_pdb'], \n",
    "            path + data['dry_dcd'], \n",
    "            frames='all', in_memory=True\n",
    "        ),\n",
    "        reference_pdy=pdy.parsePDB(path + data['dry_pdb']),\n",
    "        reference=mda.Universe(\n",
    "            path + data['dry_pdb']\n",
    "        ),\n",
    "        time=data['time']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../simulations/'\n",
    "exp01_md = []\n",
    "for key, items in md_reference_data.items():\n",
    "    print(f\"-- code {key}\", end='')\n",
    "    exp01_md.append(load_trajectory(\n",
    "        code=key, data=items, path=path\n",
    "    ))\n",
    "    print(f\" loaded\")\n",
    "exp01_md = pd.DataFrame.from_records(exp01_md).set_index('code')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSD calculations\n",
    "\n",
    "We compute the RMSD of:\n",
    "- All the alpha carbons.\n",
    "- Large subunit alpha carbons\n",
    "- Small subunit alpha carbons\n",
    "- Upper and lower large subunit alpha carbons\n",
    "- Upper and lower small subunit alpha carbons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp01_rmsd = []\n",
    "\n",
    "upper_ssu = 'name CA and (segid B or segid F or segid J or segid N)'\n",
    "lower_ssu = 'name CA and (segid D or segid H or segid L or segid P)'\n",
    "ssu = 'name CA and (segid B or segid F or segid J or segid N or segid D or segid H or segid L or segid P)'\n",
    "upper_lsu = 'name CA and (segid A or segid E or segid I or segid M)'\n",
    "lower_lsu = 'name CA and (segid C or segid G or segid K or segid O)'\n",
    "lsu = 'name CA and (segid A or segid E or segid I or segid M or segid C or segid G or segid K or segid O)'\n",
    "\n",
    "\n",
    "for key, item in exp01_md.iterrows():\n",
    "    print(f\"-- code {key}\", end='')\n",
    "    R = rms.RMSD(item['trajectory_dry'], item['reference'], select='name CA', groupselections=[upper_ssu, lower_ssu, ssu, upper_lsu, lower_lsu, lsu], superposition=False)\n",
    "    results = R.run()\n",
    "    tmp = pd.DataFrame(results.rmsd, columns=['frame', 'time', 'CA', 'upperSSU', 'lowerSSU', 'ssu', 'upperLSU', 'lowerLSU', 'lsu'])\n",
    "    tmp['code'] = key\n",
    "    exp01_rmsd.append(tmp)\n",
    "    print(f\" aligned\")\n",
    "    \n",
    "exp01_rmsd = pd.concat(exp01_rmsd)\n",
    "exp01_rmsd.index = pd.MultiIndex.from_arrays([exp01_rmsd['code'], exp01_rmsd['frame']])\n",
    "exp01_rmsd['frame'] = exp01_rmsd['frame'].astype(int)\n",
    "exp01_rmsd['time'] = exp01_rmsd['time'].astype(float)\n",
    "exp01_rmsd['time_ns'] = exp01_rmsd['time'] / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only make measurements using the last 50ns of each simulation, counting the previous 25 to 50ns as burn-in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp01_rmsd['time_to_end'] = exp01_rmsd.groupby(level='code')['time_ns'].transform(\n",
    "    lambda x: x.max() - x\n",
    ")\n",
    "exp01_rmsd.query('time_to_end < 50')['time_ns']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumping values to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp01_rmsd.to_csv(product['rmsd'], index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSD over subunits\n",
    "\n",
    "We compute the average structure RMSD by subunits.\n",
    "\n",
    "First, we need to generate all the average subunits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsu_A = 'name CA and segid A'\n",
    "lsu_E = 'name CA and segid E'\n",
    "lsu_I = 'name CA and segid I'\n",
    "lsu_M = 'name CA and segid M'\n",
    "lsu_C = 'name CA and segid C'\n",
    "lsu_G = 'name CA and segid G'\n",
    "lsu_K = 'name CA and segid K'\n",
    "lsu_O = 'name CA and segid O'\n",
    "\n",
    "ssu_B = 'name CA and segid B'\n",
    "ssu_F = 'name CA and segid F'\n",
    "ssu_J = 'name CA and segid J'\n",
    "ssu_N = 'name CA and segid N'\n",
    "ssu_D = 'name CA and segid D'\n",
    "ssu_H = 'name CA and segid H'\n",
    "ssu_L = 'name CA and segid L'\n",
    "ssu_P = 'name CA and segid P'\n",
    "\n",
    "lsu = 'name CA and (segid A or segid E or segid I or segid M or segid C or segid G or segid K or segid O)'\n",
    "ssu = 'name CA and (segid B or segid F or segid J or segid N or segid D or segid H or segid L or segid P)'\n",
    "\n",
    "selection_strings = dict(\n",
    "    overall = 'name CA',\n",
    "    ssu=ssu, \n",
    "    lsu=lsu,\n",
    "    lsu_A = lsu_A,\n",
    "    lsu_E = lsu_E,\n",
    "    lsu_I = lsu_I,\n",
    "    lsu_M = lsu_M,\n",
    "    lsu_C = lsu_C,\n",
    "    lsu_G = lsu_G,\n",
    "    lsu_K = lsu_K,\n",
    "    lsu_O = lsu_O,\n",
    "    ssu_B = ssu_B,\n",
    "    ssu_F = ssu_F,\n",
    "    ssu_J = ssu_J,\n",
    "    ssu_N = ssu_N,\n",
    "    ssu_D = ssu_D,\n",
    "    ssu_H = ssu_H,\n",
    "    ssu_L = ssu_L,\n",
    "    ssu_P = ssu_P\n",
    ")\n",
    "average_structures = dict(\n",
    "    overall=[],\n",
    "    ssu=[],\n",
    "    lsu=[],\n",
    "    lsu_A=[],\n",
    "    lsu_E=[],\n",
    "    lsu_I=[],\n",
    "    lsu_M=[],\n",
    "    lsu_C=[],\n",
    "    lsu_G=[],\n",
    "    lsu_K=[],\n",
    "    lsu_O=[],\n",
    "    ssu_B=[],\n",
    "    ssu_F=[],\n",
    "    ssu_J=[],\n",
    "    ssu_N=[],\n",
    "    ssu_D=[],\n",
    "    ssu_H=[],\n",
    "    ssu_L=[],\n",
    "    ssu_P=[]\n",
    ")\n",
    "\n",
    "for key, item in exp01_md.iterrows():\n",
    "    print(f\"-- code {key}\", end='')\n",
    "    for selection_key, selection_string in selection_strings.items():\n",
    "        try:\n",
    "            average = align.AverageStructure(\n",
    "                item['trajectory_dry'], item['trajectory_dry'], \n",
    "                select=selection_string, ref_frame=0\n",
    "            ).run()\n",
    "        except ValueError:\n",
    "            average_structures[selection_key].append(None)\n",
    "            continue\n",
    "\n",
    "        ref = average.results.universe\n",
    "        average_structures[selection_key].append(ref)\n",
    "    print(\" aligned\")\n",
    "\n",
    "exp01_md['overall_avg'] = average_structures['overall']\n",
    "exp01_md['ssu_avg'] = average_structures['ssu']\n",
    "exp01_md['lsu_avg'] = average_structures['lsu']\n",
    "\n",
    "exp01_md['lsu_A'] = average_structures['lsu_A']\n",
    "exp01_md['lsu_E'] = average_structures['lsu_E']\n",
    "exp01_md['lsu_I'] = average_structures['lsu_I']\n",
    "exp01_md['lsu_M'] = average_structures['lsu_M']\n",
    "exp01_md['lsu_C'] = average_structures['lsu_C']\n",
    "exp01_md['lsu_G'] = average_structures['lsu_G']\n",
    "exp01_md['lsu_K'] = average_structures['lsu_K']\n",
    "exp01_md['lsu_O'] = average_structures['lsu_O']\n",
    "\n",
    "exp01_md['ssu_B'] = average_structures['ssu_B']\n",
    "exp01_md['ssu_F'] = average_structures['ssu_F']\n",
    "exp01_md['ssu_J'] = average_structures['ssu_J']\n",
    "exp01_md['ssu_N'] = average_structures['ssu_N']\n",
    "exp01_md['ssu_D'] = average_structures['ssu_D']\n",
    "exp01_md['ssu_H'] = average_structures['ssu_H']\n",
    "exp01_md['ssu_L'] = average_structures['ssu_L']\n",
    "exp01_md['ssu_P'] = average_structures['ssu_P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the RMSD over the different subunit structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp01_rmsd_avg = []\n",
    "overall = 'name CA'\n",
    "\n",
    "for key, item in exp01_md.iterrows():\n",
    "    print(f\"-- code {key}\", end='')\n",
    "    R = rms.RMSD(item['trajectory_dry'], item['overall_avg'], select='name CA', groupselections=[ssu, lsu, lsu_A, lsu_E, lsu_I, lsu_M, lsu_C, lsu_G, lsu_K, lsu_O, ssu_B, ssu_F, ssu_J, ssu_N, ssu_D, ssu_H, ssu_L, ssu_P], superposition=True)\n",
    "    results = R.run()\n",
    "    tmp = pd.DataFrame(results.rmsd, columns=['frame', 'time', 'CA', 'ssu', 'lsu', 'lsu_A', 'lsu_E', 'lsu_I', 'lsu_M', 'lsu_C', 'lsu_G', 'lsu_K', 'lsu_O', 'ssu_B', 'ssu_F', 'ssu_J', 'ssu_N', 'ssu_D', 'ssu_H', 'ssu_L', 'ssu_P'])\n",
    "    tmp['code'] = key\n",
    "    \n",
    "    exp01_rmsd_avg.append(tmp)\n",
    "    print(\" aligned\")\n",
    "    \n",
    "exp01_rmsd_avg = pd.concat(exp01_rmsd_avg)\n",
    "exp01_rmsd_avg.index = pd.MultiIndex.from_arrays([exp01_rmsd_avg['code'], exp01_rmsd_avg['frame']])\n",
    "exp01_rmsd_avg['frame'] = exp01_rmsd_avg['frame'].astype(int)\n",
    "exp01_rmsd_avg['time'] = exp01_rmsd_avg['time'].astype(float)\n",
    "exp01_rmsd_avg['time_ns'] = exp01_rmsd_avg['time'] / 10\n",
    "exp01_rmsd_avg['time_to_end'] = exp01_rmsd_avg.groupby(level='code')['time_ns'].transform(\n",
    "    lambda x: x.max() - x\n",
    ")\n",
    "exp01_rmsd_avg.query('time_to_end < 50')['time_ns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp01_rmsd_avg.to_csv(\n",
    "    product['avg_rmsd'], index=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed49d9dc8263e20f82ef1c732e49d95838d00d7e343ec27a75bb1597d6166618"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
