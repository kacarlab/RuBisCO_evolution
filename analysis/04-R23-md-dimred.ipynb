{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R23 - Molecular Dynamics - Dimensionality Reduction\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Molecular Dynamics of large molecular systems, as solvated proteins, are usually challenging due to the huge number of degrees of freedom (generally, $3N -3$, where $N$ is the number of atoms). In extreme scenarios, we might work with millions of degrees of freedom. Therefore, how can we extract useful information from such a big amount of data?\n",
    "\n",
    "Although solvated proteins and other molecular systems are very big and contain many atoms, the motions of these atoms are usually restrained due to different factors: molecular bonds, local stable conformations (e.g. secondary structure), global conformations (e.g. tertiary structure), etc. Therefore, it is possible that a space with lower dimensionality is still able to describe most of the movements that we observe — in other words, particles are correlated, so we don't need to know how each of them moves at all times.\n",
    "\n",
    "The easiest path for trajectory dimensionality reduction is the linear path: using the principal component analysis on the 3D cartesian coordinates to find a set of orthogonal motions that represent how our particles move. If there are linear patterns in our trajectory, the PCA should be able to recover those as main components with large associated variances . If there are no clear patterns, then the PCA should provide a set of modes with very similar variances.\n",
    "\n",
    "The PCA is computed from the diagonalization of the covariance matrix. If our trajectory over time generates a matrix A that is [t, 3*N], then we would compute the covariance of this matrix as:\n",
    "\n",
    "$$ C = \\frac{1}{3 * N}AA^{T} $$\n",
    "\n",
    "The diagonalization of this matrix should provide a matrix P with all the modes, and a list of eigenvalues or variance-associated ratios that show how much does each of these modes represent the overall trajectory.\n",
    "\n",
    "Luckily for us, we don't need to compute the PCA manually, we can just rely on the usage of either sklearn PCA implementation or in the usage of the essential dynamics module from MDAnalysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "md_reference_data = None\n",
    "upstream = None\n",
    "product = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential Dynamics - Performing dimensionality reduction through PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import prody as pdy\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import matplotlib.pyplot as plt\n",
    "import MDAnalysis as mda\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA as sk_pca\n",
    "import matplotlib.gridspec as gridspec\n",
    "from MDAnalysis.analysis import pca as md_pca # We alias the funciton to avoid mistunderstandings\n",
    "import MDAnalysis.transformations as trans\n",
    "from MDAnalysis.analysis import align, rms, distances\n",
    "from mdtools.mapping import map_alignment_to_structure, align_structure_sequences\n",
    "\n",
    "from Bio import AlignIO\n",
    "\n",
    "from Bio.SeqUtils import seq1\n",
    "from Bio.SeqIO import SeqRecord\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_to_pc(trajectory, selection):\n",
    "    ag = trajectory.select_atoms(selection)\n",
    "    coordinates = np.stack([ag.positions.reshape(-1) for frame in trajectory.trajectory])\n",
    "    coordinates = StandardScaler(with_std=False).fit_transform(coordinates)\n",
    "    sk_pca_object = sk_pca(n_components=10)\n",
    "    sk_pca_results = sk_pca_object.fit_transform(coordinates)\n",
    "    return sk_pca_object.explained_variance_ratio_, sk_pca_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_trajectory(pdb, dcd_list):\n",
    "    trajectory = mda.Universe(\n",
    "        pdb, \n",
    "        *dcd_list\n",
    "    )\n",
    "    ag = trajectory.select_atoms('name CA')\n",
    "    coordinates = np.stack([ag.positions.reshape(-1) for frame in trajectory.trajectory])\n",
    "    coordinates = StandardScaler(with_std=False).fit_transform(coordinates)\n",
    "    sk_pca_object = sk_pca(n_components=10)\n",
    "    sk_pca_results = sk_pca_object.fit_transform(coordinates)\n",
    "    return sk_pca_results\n",
    "    \n",
    "def get_single_trajectory(trajectory, code, path, include_ssu=True):\n",
    "    \n",
    "    start_num_lsu = trajectory.select_atoms('name CA and segid A')[0].resid\n",
    "    end_num_lsu = trajectory.select_atoms('name CA and segid A')[-1].resid\n",
    "    if include_ssu:\n",
    "        try:\n",
    "            start_num_ssu = trajectory.select_atoms('name CA and segid B')[0].resid\n",
    "            end_num_ssu = trajectory.select_atoms('name CA and segid B')[-1].resid\n",
    "        except IndexError:\n",
    "            include_ssu = False\n",
    "    else:\n",
    "        pass\n",
    "    if include_ssu:\n",
    "        ag = trajectory.select_atoms(\n",
    "            'name CA and (segid A or segid E or segid I or segid M or segid C or segid G or segid K or segid O) and resid ' + str(start_num_lsu + 10) + \\\n",
    "            '-' + str(end_num_lsu - 10), 'name CA and (segid B or segid F or segid J or segid N or segid D or segid H or segid L or segid P) and resid ' + \\\n",
    "            str(start_num_ssu + 10) + '-' + str(end_num_ssu - 10))\n",
    "    else:\n",
    "        ag = trajectory.select_atoms('name CA and (segid A or segid E or segid I or segid M or segid C or segid G or segid K or segid O) and resid ' + \\\n",
    "            str(start_num_lsu + 10) + '-' + str(end_num_lsu - 10))\n",
    "    coordinates = np.stack([ag.positions.reshape(-1) for frame in trajectory.trajectory])\n",
    "    coordinates = StandardScaler(with_std=False).fit_transform(coordinates)\n",
    "    sk_pca_object = sk_pca(n_components=10)\n",
    "    sk_pca_results = sk_pca_object.fit_transform(coordinates)\n",
    "    components = sk_pca_object.components_.copy()\n",
    "    \n",
    "    return sk_pca_results, components, sk_pca_object\n",
    "\n",
    "\n",
    "def load_trajectory(code, data, path):\n",
    "    \n",
    "    \"\"\"\n",
    "    loads the following files\n",
    "    - an MDAnalysis trajectory with the dried (water-removed) dcd\n",
    "    - an MDAnalysis Universe with the starting PDB (jic)\n",
    "    - an prody with the starting PDB (pretty useful when MDAnalysis fails)\n",
    "    \"\"\"\n",
    "    return dict(\n",
    "        code=code,\n",
    "        trajectory_dry = mda.Universe(\n",
    "            path + data['dry_pdb'], \n",
    "            path + data['dry_dcd'], \n",
    "            frames='all', in_memory=True\n",
    "        ),\n",
    "        reference_pdy=pdy.parsePDB(path + data['dry_pdb']),\n",
    "        reference=mda.Universe(\n",
    "            path + data['dry_pdb']\n",
    "        ),\n",
    "        time=data['time']\n",
    "    )\n",
    "\n",
    "def map_to_protein(code, components, ref):\n",
    "    component_norm = np.linalg.norm(components.reshape([10, -1, 3]), axis=2)    # The [10, -1, 3] reshapes the components data into a 10 x X x 3 array, where -1 refers to the total number of residues/atoms that exist in the protein\n",
    "    start_num_lsu = ref.select_atoms('name CA and segid A')[0].resid\n",
    "    end_num_lsu = ref.select_atoms('name CA and segid A')[-1].resid\n",
    "    ref.add_TopologyAttr('tempfactors')\n",
    "\n",
    "    for i, res in enumerate(ref.select_atoms('protein and resid ' + str(start_num_lsu + 10) + '-' + str(end_num_lsu - 10)).residues):\n",
    "        res.atoms.tempfactors = component_norm[0, i]/(component_norm[0, :].max())\n",
    "\n",
    "    ref.select_atoms('protein').write(f'./output/{code}.pca-component0.pdb')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Trajectories with single replicates\n",
    "- 10 residue truncations are implemented at the N & C-terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../simulations/'\n",
    "exp01_md = []\n",
    "for key, items in md_reference_data.items():\n",
    "    print(f\"-- code {key}\", end='')\n",
    "    exp01_md.append(load_trajectory(\n",
    "        code=key, data=items, path=path\n",
    "    ))\n",
    "    print(f\" loaded\")\n",
    "exp01_md = pd.DataFrame.from_records(exp01_md).set_index('code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_out = []\n",
    "for key, item in exp01_md.iterrows():\n",
    "\n",
    "    lsussu_pca, lsussu_components, lsussu_pca_object = get_single_trajectory(item['trajectory_dry'], key, '../simulations/', include_ssu=True)\n",
    "    lsu_pca, lsu_components, lsu_pca_object = get_single_trajectory(item['trajectory_dry'], key, '../simulations/', include_ssu=False)\n",
    "    pca_out.append(dict(\n",
    "        code=key, \n",
    "        lsussu_pca=lsussu_pca, lsussu_variance_ratio=lsussu_pca_object.explained_variance_ratio_,\n",
    "        lsu_pca=lsu_pca, lsu_variance_ratio=lsu_pca_object.explained_variance_ratio_,\n",
    "    ))\n",
    "    # map_to_protein(key, lsussu_components, item['trajectory_dry'])\n",
    "\n",
    "pca_out = pd.DataFrame.from_records(pca_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA-plots for the motions of LSU-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, items in pca_out.iterrows():\n",
    "    pca = np.array(items['lsu_pca'])\n",
    "    g = sns.jointplot(x=pca[:, 0], y=pca[:, 1], kind='kde', joint_kws={\"fill\":True}, cmap='Spectral')\n",
    "    g.plot_joint(sns.scatterplot, color=\"black\", alpha=0.1)\n",
    "    g.fig.suptitle(items['code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the explained variance ratio with each PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, items in pca_out.iterrows():\n",
    "    sns.lineplot(x=np.arange(len(items['lsu_variance_ratio'])), y=np.array(items['lsu_variance_ratio']), marker='o', label=items['code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA-plots for the motions of both LSU and SSU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, items in pca_out.iterrows():\n",
    "    pca = np.array(items['lsussu_pca'])\n",
    "    g = sns.jointplot(x=pca[:, 0], y=pca[:, 1], kind='kde', joint_kws={\"fill\":True}, cmap='Spectral')\n",
    "    g.plot_joint(sns.scatterplot, color=\"black\", alpha=0.1)\n",
    "    g.fig.suptitle(items['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_out.to_json(product['singles_pca'], orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 independent replicates of the PCA-plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# md05_ref_data = json.load(open('./md_simulations_early_branch_rep5.json', 'r'))\n",
    "\n",
    "# path = '../../../simulations/'\n",
    "# rep_5_md = []\n",
    "# for key, items in md05_ref_data.items():\n",
    "#     print(f\"-- code {key}\", end='')\n",
    "#     rep_5_md.append(load_trajectory(\n",
    "#         code=key, data=items, path=path\n",
    "#     ))\n",
    "#     print(f\" loaded\")\n",
    "# rep_5_md = pd.DataFrame.from_records(rep_5_md).set_index('code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep5_pca_out = []\n",
    "# for key, item in rep_5_md.iterrows():\n",
    "#     lsu_pca, lsu_components, lsu_pca_object = get_single_trajectory(item['trajectory_dry'], key, '../simulations/', include_ssu=False)\n",
    "#     rep5_pca_out.append(dict(\n",
    "#         code=key, \n",
    "#         lsu_pca=lsu_pca, lsu_variance_ratio=lsu_pca_object.explained_variance_ratio_,\n",
    "#     ))\n",
    "\n",
    "# rep5_pca_out = pd.DataFrame.from_records(rep5_pca_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, items in rep5_pca_out.iterrows():\n",
    "#     pca = np.array(items['lsu_pca'])\n",
    "#     g = sns.jointplot(x=pca[:, 0], y=pca[:, 1], kind='kde', joint_kws={\"fill\":True}, cmap='Spectral')\n",
    "#     g.plot_joint(sns.scatterplot, color=\"black\", alpha=0.1)\n",
    "#     g.fig.suptitle(items['code'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential Collective Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trajectory(code, data, path):\n",
    "    return dict(\n",
    "        code=code,\n",
    "        trajectory_dry = mda.Universe(\n",
    "            path + data['dry_pdb'], \n",
    "            path + data['dry_dcd'], \n",
    "            frames='all'\n",
    "        ),\n",
    "        reference_pdy=pdy.parsePDB(path + data['dry_pdb']),\n",
    "        reference=mda.Universe(\n",
    "            path + data['dry_pdb'], in_memory=True\n",
    "        ),\n",
    "        time=data['time']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residues2sequence(residues):\n",
    "    out = \"\"\n",
    "    for res in residues:\n",
    "        resname = res.resname.replace('KCX', 'LYS')\n",
    "\n",
    "        out += seq1(resname)\n",
    "    return out\n",
    "\n",
    "def get_sequences(ref, chains):\n",
    "    sequence_bag = []\n",
    "    for chain in chains:\n",
    "        sequence_bag.append(\n",
    "            (  \n",
    "                chain,\n",
    "                residues2sequence(ref.select_atoms(f'protein and chainID {chain}').residues)\n",
    "            )\n",
    "            \n",
    "        )\n",
    "    return sequence_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../simulations/'\n",
    "md_reference_data = json.load(open('./md_simulations.json', 'r'))\n",
    "exp01_md = []\n",
    "for key, items in md_reference_data.items():\n",
    "    print(f\"-- code {key}\", end='')\n",
    "    exp01_md.append(load_trajectory(\n",
    "        code=key, data=items, path=path\n",
    "    ))\n",
    "    print(f\" loaded\")\n",
    "exp01_md = pd.DataFrame.from_records(exp01_md).set_index('code')\n",
    "a = align.AlignTraj(exp01_md.loc['ancip'].trajectory_dry, exp01_md.loc['ancip'].reference, in_memory=True, select='name CA')\n",
    "a.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp01_md['rbcl_seq'] = exp01_md['reference'].apply(lambda x: get_sequences(x, chains='ACEGIKMO'))\n",
    "exp01_md['rbcl_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_list = []\n",
    "for key, item in exp01_md['rbcl_seq'].items():\n",
    "    for chain, seq in item:\n",
    "        seq_list.append(SeqRecord(seq=Seq(seq), id='{:s}_{:s}'.format(key, chain)))\n",
    "SeqIO.write(seq_list, './output/sequence.fasta', 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mafft --maxiterate 1000 --localpair './output/sequence.fasta' > './output/sequence.aligned.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_sequences = list(pdy.MSAFile(\n",
    "    './output/sequence.aligned.fasta', format='fasta') # TODO Fix this\n",
    ")\n",
    "\n",
    "aligment_matrix = np.stack([item.getArray() for item in aligned_sequences])\n",
    "conserved_positions = []\n",
    "for i in range(aligment_matrix.shape[1]):\n",
    "    if b'-' not in np.unique(aligment_matrix[:, i]).tolist():\n",
    "        conserved_positions.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gaps(sequence):\n",
    "    for i, tokken in enumerate(sequence):\n",
    "        if tokken != '-':\n",
    "            yield i, tokken\n",
    "\n",
    "def conserved2bfactor(sequence, conserved, chain, structure):\n",
    "    # structure.add_TopologyAttr('tempfactors')\n",
    "    residues = structure.select_atoms(f'protein and chainID {chain}').residues\n",
    "    for (i, tokken), res in zip(remove_gaps(sequence), residues):\n",
    "        \n",
    "        if tokken != seq1(res.resname) and res.resname != \"HIE\":\n",
    "            # print(res.resnum, tokken, seq1(res.resname))\n",
    "            pass\n",
    "        if i in conserved:\n",
    "            try:\n",
    "                print(res.resnum, tokken, seq1(res.resname))\n",
    "                res.atoms.tempfactors = 1.0\n",
    "            except AttributeError:\n",
    "                print(f\"{i} {tokken} {res.resname}\")\n",
    "        else:\n",
    "            res.atoms.tempfactors = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in aligned_sequences:\n",
    "    key = seq.getLabel()\n",
    "    protein = key.split()[0].split('_')[0]\n",
    "    chain = key.split()[0].split('_')[1]\n",
    "    item = exp01_md.loc[protein]\n",
    "    print(protein, chain)\n",
    "    conserved2bfactor(\n",
    "        str(seq), conserved_positions, chain, item.trajectory_dry\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_buffer = []\n",
    "label_buffer = []\n",
    "frame_buffer = []\n",
    "scaler = StandardScaler(with_std=False)\n",
    "\n",
    "for key, item in exp01_md.iterrows():\n",
    "    protein_positions_buffer = []\n",
    "    for i, frame in enumerate(item.trajectory_dry.trajectory):\n",
    "        tmp_positions = []\n",
    "        for chain in 'ACEIGKMO':\n",
    "            g = item.trajectory_dry.select_atoms(f'protein and prop tempfactor > 0.0 and name CA and chainID {chain}')\n",
    "            positions = g.positions\n",
    "            tmp_positions.append(positions)\n",
    "            \n",
    "        tmp_positions = np.stack(tmp_positions).reshape(-1)\n",
    "        protein_positions_buffer.append(tmp_positions)\n",
    "        label_buffer.append(key)\n",
    "        frame_buffer.append(i)\n",
    "    \n",
    "    # protein_positions_buffer = scaler.fit_transform(np.stack(protein_positions_buffer))\n",
    "    positions_buffer.append(np.stack(protein_positions_buffer))\n",
    "\n",
    "positions_buffer = np.concatenate(positions_buffer)\n",
    "# label_buffer = label_buffer\n",
    "frame_buffer = np.array(frame_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_buffer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(positions_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sk_pca(n_components=10, whiten=False)\n",
    "scaler = StandardScaler(with_mean=True, with_std=False)\n",
    "\n",
    "X = scaler.fit_transform(positions_buffer)\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "fig.set_size_inches(3, 3)\n",
    "ax.plot(np.arange(1, 11), pca.explained_variance_ratio_.cumsum(), marker='o', color='black')\n",
    "ax.set_xlabel('Eigenvector index')\n",
    "ax.set_ylabel('Variance explained (%)')\n",
    "ax.set_ylim(None, 1.0)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\n",
    "    product['joint_pca_variance'],\n",
    "    pca.explained_variance_ratio_.cumsum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_pca = pd.DataFrame.from_dict(dict(pca_x=X[:,0], pca_y=X[:, 1], pca_z=X[:, 2], time=frame_buffer, label=label_buffer))\n",
    "md_pca.to_json(product['joint_pca'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(md_pca[['pca_x', 'pca_y', 'pca_z', 'label']], hue='label', plot_kws={\"alpha\":0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = sns.pairplot(md_pca[['pca_x', 'pca_y', 'pca_z', 'time']], hue='time', diag_kind=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "md-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31308ec8134b1b7699017ca6d9032a2147384e07e46424fffb4eaac307ef9720"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
